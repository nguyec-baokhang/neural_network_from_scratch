{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import pathlib\n",
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = 'archive/train-images.idx3-ubyte'\n",
    "y_train = 'archive/train-labels.idx1-ubyte'\n",
    "X_test = 'archive/t10k-images.idx3-ubyte'\n",
    "y_test = 'archive/t10k-labels.idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = idx2numpy.convert_from_file(X_train)\n",
    "y_train = idx2numpy.convert_from_file(y_train)\n",
    "X_test = idx2numpy.convert_from_file(X_test)\n",
    "y_test = idx2numpy.convert_from_file(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28 * 28)\n",
    "X_test = X_test.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerDense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights = 0.1*np.random.randn(n_inputs,n_neurons)\n",
    "        self.biases = np.zeros((1,n_neurons))\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self,dvalues): \n",
    "        self.dweights = np.dot(self.inputs.T,dvalues)\n",
    "        self.dbiases = np.sum(dvalues,axis=0,keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Relu:\n",
    "    def forward(self,inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        return self.output\n",
    "    def backward(self,dvalues): \n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax: \n",
    "    def forward(self,layer_outputs): \n",
    "        exp_values = np.exp(layer_outputs - np.max(layer_outputs, keepdims= True, axis= 1))\n",
    "        probabilities = exp_values / (np.sum(exp_values, keepdims=True, axis=1))\n",
    "        self.output = probabilities\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self,dvalues): \n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        for index,(single_output, single_dvalues) in enumerate(zip(self.output,dvalues)): \n",
    "            single_output = single_output.reshape(-1,1)\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output,single_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,single_dvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss: \n",
    "    def calculate(self, output, y): \n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "    \n",
    "class Loss_CategoricalCrossEntropy(Loss):\n",
    "    def forward(self, y_pred, y_true): \n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1: \n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2: \n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        neg_log_likelihoods = -np.log(correct_confidences)\n",
    "\n",
    "        return neg_log_likelihoods\n",
    "    \n",
    "    def backward(self,dvalues,y_true): \n",
    "        samples = len(dvalues)\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        if len(y_true.shape) == 1: \n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        self.dinputs = -y_true/dvalues\n",
    "        self.dinputs = self.dinputs/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax_Loss_CategoricalCrossEntropy: \n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossEntropy()\n",
    "\n",
    "    def forward(self,inputs,y_true): \n",
    "        self.activation.forward(inputs)\n",
    "        self.output = self.activation.output\n",
    "        return self.loss.calculate(self.output,y_true)\n",
    "    \n",
    "    def backward(self,dvalues,y_true): \n",
    "        samples = len(dvalues)\n",
    "\n",
    "        if len(y_true.shape) == 2: \n",
    "            y_true = np.argmax(y_true,axis=1)\n",
    "\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[range(samples),y_true] -= 1\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer_SGD: \n",
    "    def __init__(self,lr=1.0):\n",
    "        self.lr = lr \n",
    "\n",
    "    def update_params(self,layer): \n",
    "        layer.weights += -self.lr * layer.dweights \n",
    "        layer.biases += -self.lr * layer.dbiases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(LayerDense, Activation_Relu, Activation_Softmax, Loss_CategoricalCrossEntropy): \n",
    "    def __init__(self,n_inputs,n_neurons,n_outputs):\n",
    "        self.layer1 = LayerDense(n_inputs,n_neurons)\n",
    "        self.layer2 = LayerDense(n_neurons,n_outputs)\n",
    "        self.activation1 = Activation_Relu() \n",
    "        self.activation2 = Activation_Softmax()\n",
    "\n",
    "    def forward(self,inputs): \n",
    "        self.Z1 = self.layer1.forward(inputs)\n",
    "        self.A1 = self.activation1.forward(self.Z1)\n",
    "        self.Z2 = self.layer2.forward(self.A1)\n",
    "        self.A2 = self.activation2.forward(self.Z2)\n",
    "        return self.A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(index,model,X,y): \n",
    "    current_image = X[index:index+1]\n",
    "    softmax_output = model.forward(current_image)\n",
    "    prediction = np.argmax(softmax_output)\n",
    "    label = y[index]\n",
    "    print(f\"Predictions: {prediction}\")\n",
    "    print(f\"Label: {label}\")\n",
    "\n",
    "    current_image = current_image.reshape((28,28))\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation=\"nearest\")\n",
    "    plt.title(f\"Predicted: {prediction}, Actual: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Accuracy: 0.095| Loss: 2.3033748367721847 \n",
      "Epoch: 100| Accuracy: 0.720| Loss: 1.7756359125714087 \n",
      "Epoch: 200| Accuracy: 0.750| Loss: 1.7199918795989455 \n",
      "Epoch: 300| Accuracy: 0.758| Loss: 1.708267585533508 \n",
      "Epoch: 400| Accuracy: 0.763| Loss: 1.70241693780936 \n",
      "Epoch: 500| Accuracy: 0.831| Loss: 1.642781535799706 \n",
      "Epoch: 600| Accuracy: 0.843| Loss: 1.626054520810554 \n",
      "Epoch: 700| Accuracy: 0.848| Loss: 1.6200229927009107 \n",
      "Epoch: 800| Accuracy: 0.850| Loss: 1.616577843082599 \n",
      "Epoch: 900| Accuracy: 0.852| Loss: 1.6141431746016452 \n",
      "Epoch: 1000| Accuracy: 0.853| Loss: 1.6122396804081598 \n",
      "Epoch: 1100| Accuracy: 0.855| Loss: 1.6106517528236557 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m| Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m| Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[1;32m     19\u001b[0m loss_fn\u001b[38;5;241m.\u001b[39mbackward(loss_fn\u001b[38;5;241m.\u001b[39moutput, y_train)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdinputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m model_1\u001b[38;5;241m.\u001b[39mlayer2\u001b[38;5;241m.\u001b[39mbackward(model_1\u001b[38;5;241m.\u001b[39mactivation2\u001b[38;5;241m.\u001b[39mdinputs)\n\u001b[1;32m     22\u001b[0m model_1\u001b[38;5;241m.\u001b[39mactivation1\u001b[38;5;241m.\u001b[39mbackward(model_1\u001b[38;5;241m.\u001b[39mlayer2\u001b[38;5;241m.\u001b[39mdinputs)\n",
      "Cell \u001b[0;32mIn[109], line 13\u001b[0m, in \u001b[0;36mActivation_Softmax.backward\u001b[0;34m(self, dvalues)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,(single_output, single_dvalues) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput,dvalues)): \n\u001b[1;32m     12\u001b[0m     single_output \u001b[38;5;241m=\u001b[39m single_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     jacobian_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiagflat(single_output) \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43msingle_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdinputs[index] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(jacobian_matrix,single_dvalues)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_1 = Neural_Network(784,10,10)\n",
    "loss_fn = Activation_Softmax_Loss_CategoricalCrossEntropy() \n",
    "optimizer = Optimizer_SGD(lr=1.0) \n",
    "\n",
    "epochs = 10001 \n",
    "\n",
    "for epoch in range(epochs): \n",
    "    softmax_output = model_1.forward(X_train)\n",
    "    loss = loss_fn.forward(softmax_output,y_train)\n",
    "\n",
    "    predictions = np.argmax(softmax_output, axis=1)\n",
    "    if len(y_train.shape) == 2: \n",
    "        y_train = np.argmax(y_train,axis=1)\n",
    "    accuracy = np.mean(predictions == y_train)\n",
    "\n",
    "    if epoch % 100 == 0: \n",
    "        print(f\"Epoch: {epoch}| Accuracy: {accuracy:.3f}| Loss: {loss} \")   \n",
    "\n",
    "    loss_fn.backward(loss_fn.output, y_train)\n",
    "    model_1.activation2.backward(loss_fn.dinputs)\n",
    "    model_1.layer2.backward(model_1.activation2.dinputs)\n",
    "    model_1.activation1.backward(model_1.layer2.dinputs)\n",
    "    model_1.layer1.backward(model_1.activation1.dinputs)\n",
    "\n",
    "    optimizer.update_params(model_1.layer1)\n",
    "    optimizer.update_params(model_1.layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 6\n",
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(130,model_1,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
